Running in parallel on 20 cores
*** TESTING GRADIENT ADJOINT ***
Now performing an optimization...

step size: 1e-10
Adjoint FOM: 1.9521019707102925
Adjoint gradient: [1759.97286517]

FD FOM: 1.9502885916670292
FD gradient: [-628.8358622708046]

Now performing an optimization...

step size: 1e-09
Adjoint FOM: 1.9521020840309693
Adjoint gradient: [1759.97016227]

FD FOM: 1.950288970700017
FD gradient: [-132.296175126001]

Now performing an optimization...

step size: 1e-08
Adjoint FOM: 1.9521017250032267
Adjoint gradient: [1759.96842848]

FD FOM: 1.9502889460108428
FD gradient: [-37.59357298793731]

Now performing an optimization...

step size: 1e-07
Adjoint FOM: 1.9521019891559515
Adjoint gradient: [1759.96325909]

FD FOM: 1.9502887872626151
FD gradient: [1.1676747158073653]

Now performing an optimization...

step size: 1e-06
Adjoint FOM: 1.9521016078609443
Adjoint gradient: [1759.86740771]

FD FOM: 1.9502891857644726
FD gradient: [-0.10906502967422682]

Now performing an optimization...

step size: 1e-05
Adjoint FOM: 1.9521007936356338
Adjoint gradient: [1758.95639413]

FD FOM: 1.9502876792864468
FD gradient: [0.02705006163505885]

Now performing an optimization...

step size: 0.0001
Adjoint FOM: 1.9521013937591878
Adjoint gradient: [1749.70089427]

FD FOM: 1.9502809312606746
FD gradient: [0.013193217468510099]

Now performing an optimization...

step size: 0.001
Adjoint FOM: 1.9521017711263466
Adjoint gradient: [1657.79273637]

FD FOM: 1.9502047811633942
FD gradient: [0.011159932066795442]

Now performing an optimization...
..
----------------------------------------------------------------------
Ran 2 tests in 3429.432s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.469s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.464s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.454s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.487s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.465s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.440s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.483s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.432s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.439s

OK
....
----------------------------------------------------------------------
Ran 2 tests in 3429.496s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.440s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.494s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.441s

OK
....
----------------------------------------------------------------------
Ran 2 tests in 3429.465s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.456s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.459s

OK

----------------------------------------------------------------------
Ran 2 tests in 3429.451s

OK

----------------------------------------------------------------------
Ran 2 tests in 3429.507s

OK
..
----------------------------------------------------------------------
Ran 2 tests in 3429.480s

OK

step size: 0.01
Adjoint FOM: 1.9521021082270102
Adjoint gradient: [762.96844005]

FD FOM: 1.9481940814547025
FD gradient: [0.008281579348434764]

