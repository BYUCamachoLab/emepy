Running in parallel on 10 cores
current state: start
  0%|          | 0/42 [00:00<?, ?it/s]100%|██████████| 42/42 [00:00<00:00, 2486.46it/s]
current state: mode_solving
0it [00:00, ?it/s]1it [01:06, 66.36s/it]2it [08:09, 276.41s/it]3it [10:21, 210.37s/it]4it [12:23, 175.40s/it]5it [14:16, 153.03s/it]5it [14:16, 171.35s/it]
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
SystemError: Negative size passed to PyBytes_FromStringAndSize
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
SystemError: Negative size passed to PyBytes_FromStringAndSize
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
SystemError: Negative size passed to PyBytes_FromStringAndSize
SystemError: Negative size passed to PyBytes_FromStringAndSize
SystemError: Negative size passed to PyBytes_FromStringAndSize
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
SystemError: Negative size passed to PyBytes_FromStringAndSize
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
SystemError: Negative size passed to PyBytes_FromStringAndSize
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
SystemError: Negative size passed to PyBytes_FromStringAndSize
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
Traceback (most recent call last):
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    return _run_code(code, main_globals, None,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    exec(code, run_globals)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/__main__.py", line 7, in <module>
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    main()
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 198, in main
    run_command_line(args)
  File "/fslhome/ihammond/.local/lib/python3.9/site-packages/mpi4py/run.py", line 47, in run_command_line
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    run_path(sys.argv[0], run_name='__main__')
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 268, in run_path
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    return _run_module_code(code, init_globals, run_name,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 97, in _run_module_code
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    _run_code(code, mod_globals, init_globals,
  File "/fslhome/ihammond/miniconda3/envs/emepy/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "adiabatic.py", line 79, in <module>
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    eme.propagate()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 550, in propagate
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
SystemError: Negative size passed to PyBytes_FromStringAndSize
    self.solve_modes()
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 153, in solve_modes
    results = self._run_parallel_functions(*tasks)
  File "/zhome/ihammond/GitHub/emepy/emepy/eme.py", line 618, in _run_parallel_functions
    finished_tasks_collective = self.comm.allgather(new_data)
  File "mpi4py/MPI/Comm.pyx", line 1595, in mpi4py.MPI.Comm.allgather
  File "mpi4py/MPI/msgpickle.pxi", line 863, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 868, in mpi4py.MPI.PyMPI_allgather
  File "mpi4py/MPI/msgpickle.pxi", line 191, in mpi4py.MPI.pickle_allocv
  File "mpi4py/MPI/msgpickle.pxi", line 182, in mpi4py.MPI.pickle_alloc
SystemError: Negative size passed to PyBytes_FromStringAndSize
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 8 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
[m8-2-4.rc.byu.edu:27671] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[m8-2-4.rc.byu.edu:27671] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
